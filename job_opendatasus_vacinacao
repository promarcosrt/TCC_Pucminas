import sys
import boto3
import logging
import pandas as pd

import pyspark.sql.functions as F
from pyspark.sql.functions import *
from pyspark.sql.types import *
from awsglue.job import Job

from awsglue.context import GlueContext
from pyspark.context import SparkContext
from awsglue.utils import getResolvedOptions

sc = SparkContext.getOrCreate()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

def carga_vacinas():
    
    try:
        print("Inicio dados Brutos")
        df = spark.read.option("header","True").option("delimiter",";").csv("s3://opendatasus.puc.raw/vacinacao/part-00000*.csv")
        df = df.withColumn("cod_sistema_origem",sha2(col("sistema_origem"),256))
        df = df.withColumn("cod_dose",sha2(col("vacina_descricao_dose"),256))
        df = df.withColumn("cod_estabelecimento",col("estabelecimento_valor"))
        df = df.withColumn("cod_grupo",col("vacina_grupoAtendimento_codigo"))
        df = df.withColumn("cod_categoria",col("vacina_categoria_codigo"))
        df = df.withColumn("cod_vacina",col("vacina_codigo"))
        df = df.withColumn("cod_paciente",col("paciente_id"))
        df = df.withColumn("cod_raca",col("paciente_racaCor_codigo"))
        df = df.withColumn("cod_municipio_estab",col("paciente_endereco_coIbgeMunicipio"))
        df = df.withColumn("cod_municipio_paciente",col("estabelecimento_municipio_codigo"))
        df = df.withColumn("data_aplicacao",date_format(to_date(col("vacina_dataAplicacao"),"yyyy-MM-dd"),'dd/MM/yyyy'))
        df = df.withColumn("data",to_date(col("vacina_dataAplicacao"),"yyyy-MM-dd"))
        print("Dados com chaves")
        
        return df
        
    except Exception as e:
        print(f"ERROR: {e}")

def fato_vacinas(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio fato")
        df_fato = spark.sql("""
        SELECT
            cod_sistema_origem
            ,cod_estabelecimento
            ,cod_grupo
            ,cod_categoria
            ,cod_vacina
            ,cod_paciente
            ,cod_raca
            ,cod_dose
            ,cod_municipio_estab
            ,cod_municipio_paciente
            ,data_aplicacao
            ,count(distinct document_id) as Qtd_Vacinas_Aplicadas
        FROM df
        group by
            cod_sistema_origem
            ,cod_estabelecimento
            ,cod_grupo
            ,cod_categoria
            ,cod_vacina
            ,cod_paciente
            ,cod_raca
            ,cod_dose
            ,cod_municipio_estab
            ,cod_municipio_paciente
            ,data_aplicacao        
        """)
        
        df_fato.write.mode("overwrite").partitionBy("cod_sistema_origem","cod_dose","cod_municipio_estab").\
        format("parquet").save("s3://opendatasus.puc.structured/vacinacao/fato_vacinas")
        print("fato atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
    
def dm_sistemas(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao sistemas")
        
        df_sistemas = spark.sql("""
        SELECT distinct
            cod_sistema_origem
            ,sistema_origem
        FROM df
        where sistema_origem is not null
        """)
        
        df_sistemas.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_sistemas")
        
        print("dimensao sistemas atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
        
def dm_doses(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao doses")
        
        df_doses = spark.sql("""
        SELECT distinct
            cod_dose
            ,vacina_descricao_dose
        FROM df
        where vacina_descricao_dose is not null
        """)
        
        df_doses.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_doses")
        
        print("dimensao doses atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
        
def dm_paciente(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao paciente")
        
        df_paciente = spark.sql("""
        SELECT distinct
            cod_paciente
            ,paciente_idade as idade
            ,date_format(to_date(paciente_dataNascimento,'yyyy-MM-dd'),'dd/MM/yyyy') as data_nascimento
            ,paciente_enumSexoBiologico as sexo
            ,paciente_nacionalidade_enumNacionalidade as nacionalidade
            ,paciente_endereco_cep as cep
        FROM df
        where cod_paciente is not null
        """)
        
        df_paciente.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_paciente")
        
        print("dimensao paciente atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
        
def dm_estabelecimento(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao estabelecimento")
        
        df_estabelecimento = spark.sql("""
        SELECT distinct
            cod_estabelecimento
            ,estabelecimento_razaoSocial as razao_social
            ,estalecimento_noFantasia as nome_fantasia
        FROM df
        where cod_estabelecimento is not null
        """)
        
        df_estabelecimento.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_estabelecimento")
        
        print("dimensao estabelecimento atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
        
def dm_vacina(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao vacina")
        
        df_vacina = spark.sql("""
        SELECT distinct
            cod_vacina
            ,vacina_nome as nome_vacina
            ,vacina_fabricante_nome as nome_fabricante
        FROM df
        where cod_vacina is not null
        """)
        
        df_vacina.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_vacina")
        
        print("dimensao vacina atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}") 
        
def dm_grupo(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao grupo")
        
        df_grupo = spark.sql("""
        SELECT distinct
            cod_grupo
            ,vacina_grupoAtendimento_nome as desc_grupo
        FROM df
        where cod_grupo is not null
        """)
        
        df_grupo.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_grupo")
        
        print("dimensao grupo atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")
        
def dm_categoria(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao categoria")
        
        df_categoria = spark.sql("""
        SELECT distinct
            cod_categoria
            ,vacina_categoria_nome as desc_categoria
        FROM df
        where cod_categoria is not null
        """)
        
        df_categoria.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_categoria")
        
        print("dimensao categoria atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}") 
        
def dm_raca(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao raca")
        
        df_raca = spark.sql("""
        SELECT distinct
            cod_raca
            ,paciente_racaCor_valor as desc_raca
        FROM df
        where cod_raca is not null
        """)
        
        df_raca.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_raca")
        
        print("dimensao raca atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")

def dm_regiao_estab(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao regiao estab")
        
        df_regiao_estab = spark.sql("""
        SELECT distinct
            cod_municipio_estab
            ,estabelecimento_municipio_nome as desc_municipio
            ,estabelecimento_uf as desc_uf
        FROM df
        where cod_municipio_estab is not null
        """)
        
        df_regiao_estab.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_regiao_estab")
        
        print("dimensao regiao estab atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}") 
        
def dm_regiao_paciente(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao regiao paciente")
        
        df_regiao_paciente = spark.sql("""
        SELECT distinct
            cod_municipio_paciente
            ,paciente_endereco_nmMunicipio as desc_municipio
            ,paciente_endereco_uf as desc_uf
            ,paciente_endereco_nmPais as desc_pais
        FROM df
        where cod_municipio_paciente is not null
        """)
        
        df_regiao_paciente.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_regiao_paciente")
        
        print("dimensao regiao paciente atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")  
        
def dm_data(df):

    try:
        
        df.createOrReplaceTempView("df")
        
        print("Inicio dimensao data")
        
        df_data = spark.sql("""
        SELECT distinct
            data_aplicacao
            ,lpad(day(data),2,'0') as dia
            ,lpad(month(data),2,'0') as mes
            ,year(data) as ano
            ,lpad(date_format(data,'w'),2,'0') as semana
            ,concat(lpad(month(data),2,'0'),'_',year(data)) as mes_ano
        FROM df
        where data is not null
        """)
        
        df_data.write.mode("overwrite").format("parquet").save("s3://opendatasus.puc.structured/vacinacao/dm_data")
        
        print("dimensao data atualizada!")
        
    except Exception as e:
        print(f"ERROR: {e}")          

def main():
    
    df_dados = carga_vacinas()
    
    fato_vacinas(df_dados)
    dm_sistemas(df_dados)
    dm_doses(df_dados)
    dm_paciente(df_dados)
    dm_estabelecimento(df_dados)
    dm_vacina(df_dados)
    dm_grupo(df_dados)
    dm_categoria(df_dados)
    dm_raca(df_dados)
    dm_regiao_estab(df_dados)
    dm_regiao_paciente(df_dados)
    dm_data(df_dados)

if __name__ == "__main__":
    main()
    
